{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewAgeU_Ygyjz"
      },
      "source": [
        "Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjn6Gp88Xi1s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('Final_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRJxmi3Ng19H"
      },
      "source": [
        "Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGvm0A26Xk5v",
        "outputId": "da551e8b-3773-499e-defc-3c58e8fafec8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "data_copy = data\n",
        "data_types = data_copy.dtypes\n",
        "\n",
        "print(data.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "susOtZyGXpnc"
      },
      "outputs": [],
      "source": [
        "data_copy = data_copy.dropna(subset=['odometer', 'manufacturer', 'model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tklf6GyTXvHE"
      },
      "outputs": [],
      "source": [
        "data_copy.fillna('unknown', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq3QbIebXwiM"
      },
      "outputs": [],
      "source": [
        "data_copy = data_copy.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej3wO7a1X0RU"
      },
      "outputs": [],
      "source": [
        "manufacturer_values = data_copy['manufacturer'].value_counts()\n",
        "data_copy['manufacturer'] =  data_copy['manufacturer'].apply(lambda x: x if str(x) in manufacturer_values[:20] else 'others')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS8WtRHpX1rX"
      },
      "outputs": [],
      "source": [
        "region_values = data_copy['region'].value_counts()\n",
        "data_copy['region'] = data_copy['region'].apply(lambda x: x if str(x) in region_values[:50] else 'others')\n",
        "model_values = data_copy['model'].value_counts()\n",
        "data_copy['model'] = data_copy['model'].apply(lambda x: x if str(x) in model_values[:50] else 'others')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCLrGbQ1X3v5"
      },
      "outputs": [],
      "source": [
        "price_percentile25 = data_copy['price'].quantile(0.25)\n",
        "price_percentile75 = data_copy['price'].quantile(0.75)\n",
        "price_iqr = price_percentile75 - price_percentile25\n",
        "price_upper_limit = price_percentile75 + 1.5 * price_iqr\n",
        "price_lower_limit = data_copy['price'].quantile(0.15)\n",
        "new_df = data_copy[(data_copy['price'] < price_upper_limit) & (data_copy['price'] > price_lower_limit)]\n",
        "odometer_percentile75 = data_copy['odometer'].quantile(0.75)\n",
        "odometer_percentile25 = data_copy['odometer'].quantile(0.25)\n",
        "odometer_iqr = odometer_percentile75 - odometer_percentile25\n",
        "odometer_upper_limit = odometer_percentile75 + 1.5 * odometer_iqr\n",
        "odometer_lower_limit = data_copy['odometer'].quantile(0.05)\n",
        "new_df = new_df[(new_df['odometer'] < odometer_upper_limit) & (new_df['odometer'] > odometer_lower_limit)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTvumevzX6Rm",
        "outputId": "1c38600f-936d-468c-e4f5-60246ec09f51"
      },
      "outputs": [],
      "source": [
        "new_df['odometer'] = new_df['odometer'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpI6crcTX8NW"
      },
      "outputs": [],
      "source": [
        "# new_df = new_df[new_df['year'] > 1996]\n",
        "# new_df.shape\n",
        "# new_df['car_age'] = 2022 - new_df['year']\n",
        "# new_df.drop(['year'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spn43i9QYAgF"
      },
      "outputs": [],
      "source": [
        "final_df = new_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqdVvShag5A9"
      },
      "source": [
        "Split data into Train and Test and also deal with categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aN8vp-j2gGet"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_encoded = pd.get_dummies(final_df, columns=['region', 'manufacturer', 'model', 'condition', 'cylinders',\n",
        "                                         'fuel', 'title_status', 'transmission', 'drive', 'type', 'paint_color'])\n",
        "\n",
        "X = df_encoded.drop('price', axis=1)\n",
        "y = df_encoded['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZDpy9nmYCtd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(final_df.drop(['price'], axis = 1), final_df['price'], random_state = 42, test_size = .2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4zA4o0YYzaD"
      },
      "source": [
        "### Running XGBoost without any distributed training and without Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRoU2JjGYy8V",
        "outputId": "a9f12ebd-5fd6-451f-a043-d66f6593bd8e"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Convert the dataset into an optimized data structure called Dmatrix that XGBoost supports\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
        "\n",
        "# Specify parameters (there are a lot of tuning options here)\n",
        "params = {\n",
        "    'max_depth': 3,  # the maximum depth of each tree\n",
        "    'eta': 0.3,  # the training step for each iteration\n",
        "    'objective': 'reg:squarederror',  # regression with squared loss\n",
        "    'num_boost_round': 1000  # the number of boosting rounds or trees to build\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "start = time.time()\n",
        "bst = xgb.train(params, dtrain, num_boost_round=params['num_boost_round'])\n",
        "end = time.time()\n",
        "print(\"Training time in seconds: \")\n",
        "print(end - start)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = bst.predict(dtest)\n",
        "\n",
        "# Calculate and print the mean squared error\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll1xxixgmI5R",
        "outputId": "3b997039-a262-44b1-e92c-45930ae4c2a8"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnTXtJmM1Wta"
      },
      "source": [
        "### Running XGBoost with Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01vloFUcbM5X"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col\n",
        "from xgboost.spark import SparkXGBRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import time\n",
        "\n",
        "# Initialize Spark Session\n",
        "# spark = SparkSession.builder.appName(\"XGBoostRegressor\").getOrCreate()\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"XGBoostRegressor\") \\\n",
        "    .master(\"local[2]\") \\\n",
        "    .config(\"spark.executor.cores\", \"2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load your data into a Spark DataFrame (assuming df is your pandas DataFrame)\n",
        "sdf = spark.createDataFrame(df_encoded)\n",
        "\n",
        "# Convert columns to features column (VectorAssembler is used to transform the input columns to a single vector column)\n",
        "assembler = VectorAssembler(inputCols=[c for c in sdf.columns if c != 'price'], outputCol=\"features\")\n",
        "sdf_transformed = assembler.transform(sdf)\n",
        "\n",
        "# Define the label column\n",
        "sdf_transformed = sdf_transformed.withColumnRenamed(\"price\", \"label\")\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "train, test = sdf_transformed.randomSplit([0.8, 0.2], seed=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zof-j-VEpeB"
      },
      "outputs": [],
      "source": [
        "spark.conf.set(\"spark.sql.legacy.setCommandRejectsSparkCoreConfs\",\"false\")\n",
        "spark.conf.set(\"spark.executor.cores\", \"1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrl7rUvIEpZa",
        "outputId": "cf9d51c6-2422-4ece-cd27-39223549dead"
      },
      "outputs": [],
      "source": [
        "spark.conf.set(\"spark.sql.legacy.setCommandRejectsSparkCoreConfs\",\"false\")\n",
        "num_repeat = 10\n",
        "max_worker = 4\n",
        "\n",
        "\n",
        "run_time, R2, RMSE = {}, {}, {}\n",
        "for num_worker in range(1,max_worker+1):\n",
        "  print(f\"num_worker={num_worker}\")\n",
        "  spark.conf.set(\"spark.executor.cores\", str(num_worker))\n",
        "  run_time[num_worker] = []\n",
        "  R2[num_worker] = []\n",
        "  RMSE[num_worker] = []\n",
        "\n",
        "  for _ in range(num_repeat):\n",
        "    spark_reg_estimator = SparkXGBRegressor(\n",
        "        features_col=\"features\",\n",
        "        label_col=\"label\",\n",
        "        numWorkers=num_worker,  # number of workers; adjust based on your cluster\n",
        "        maxDepth=3,\n",
        "        eta=0.3,\n",
        "        objective='reg:squarederror',\n",
        "        numRound=1000\n",
        "    )\n",
        "    # Train the model\n",
        "    start = time.time()\n",
        "    spark_model = spark_reg_estimator.fit(train)\n",
        "    end = time.time()\n",
        "    run_time[num_worker].append(end - start)\n",
        "    # Predict the labels of the test set\n",
        "    predictions = spark_model.transform(test)\n",
        "\n",
        "    # Evaluate the model for RMSE\n",
        "    evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "    rmse_tmp = evaluator_rmse.evaluate(predictions)\n",
        "    RMSE[num_worker].append(rmse_tmp)\n",
        "\n",
        "    # Evaluate the model for R-squared\n",
        "    evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "    r2_tmp = evaluator_r2.evaluate(predictions)\n",
        "    R2[num_worker].append(r2_tmp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(run_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmZ4AjmQEpUf"
      },
      "outputs": [],
      "source": [
        "!pip3 install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S68NdfclEpSS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = []\n",
        "for num_workers, times in run_time.items():\n",
        "    for time in times:\n",
        "        data.append({'number_workers': num_workers, 'run_time': time})\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the boxplot\n",
        "sns.boxplot(x='number_workers', y='run_time', data=df, palette='RdPu')\n",
        "\n",
        "# Labeling the axes\n",
        "plt.xlabel('Number of Workers(Cores)')\n",
        "plt.ylabel('Run Time (seconds)')\n",
        "plt.savefig('temp2.jpeg', format='jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaW9t_PSvRjt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pRXpZ-l2hA0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
