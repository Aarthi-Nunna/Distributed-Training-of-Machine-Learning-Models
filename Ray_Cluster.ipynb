{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsroshAvX79X"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"ray[default]\" google-api-python-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Ray - Test Code To execute Tasks on 2 CPUs**"
      ],
      "metadata": {
        "id": "bGyHcCIT3Xai"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXTk1vRKYSF4",
        "outputId": "0e4dd668-f003-4939-850b-80939c494401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-12-04 03:33:37,953\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This cluster consists of\n",
            "    1 nodes in total\n",
            "    2.0 CPU resources in total\n",
            "\n",
            "Tasks executed\n",
            "    10000 tasks on 172.28.0.12\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import socket\n",
        "import time\n",
        "\n",
        "import ray\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "\n",
        "print('''This cluster consists of\n",
        "    {} nodes in total\n",
        "    {} CPU resources in total\n",
        "'''.format(len(ray.nodes()), ray.cluster_resources()['CPU']))\n",
        "\n",
        "@ray.remote\n",
        "def f():\n",
        "    time.sleep(0.001)\n",
        "    # Return IP address.\n",
        "    return socket.gethostbyname(socket.gethostname())\n",
        "\n",
        "object_ids = [f.remote() for _ in range(10000)]\n",
        "ip_addresses = ray.get(object_ids)\n",
        "\n",
        "print('Tasks executed')\n",
        "for ip_address, num_tasks in Counter(ip_addresses).items():\n",
        "    print('    {} tasks on {}'.format(num_tasks, ip_address))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKkofewYefRx"
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQbCAX3ifOnX"
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default set-quota-project divine-beanbag-406919"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a Ray Cluster on GCP using config.yaml**"
      ],
      "metadata": {
        "id": "t3MJovyb3qky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJiTagdrciwJ"
      },
      "outputs": [],
      "source": [
        "!ray up -y config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF8dhYdcrqg_"
      },
      "outputs": [],
      "source": [
        "!ray exec config.yaml 'python -c \"import ray; ray.init()\"'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4JH90AsuBDO",
        "outputId": "72a31439-e35a-4686-955a-d2cb2b52fd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Autoscaler status: 2023-12-04 02:55:27.196839 ========\n",
            "Node status\n",
            "---------------------------------------------------------------\n",
            "Active:\n",
            " 1 node_27f80b26f2c16bde1040cacb5c76a564cce90b194af90190b6ce2ded\n",
            "Pending:\n",
            " (no pending nodes)\n",
            "Recent failures:\n",
            " (no failures)\n",
            "\n",
            "Resources\n",
            "---------------------------------------------------------------\n",
            "Usage:\n",
            " 0.0/2.0 CPU\n",
            " 0B/7.34GiB memory\n",
            " 0B/3.67GiB object_store_memory\n",
            "\n",
            "Demands:\n",
            " (no resource demands)\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!ray status"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing and Model Training"
      ],
      "metadata": {
        "id": "Q2W-BrnE4E-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cddgWBruvyic",
        "outputId": "3e8f3891-f0bf-46cf-f913-04b355258450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   region  price    year manufacturer                        model  condition  \\\n",
            "0  auburn  15000  2013.0         ford                    f-150 xlt  excellent   \n",
            "1  auburn  30990  2019.0         ford   ranger supercrew xl pickup       good   \n",
            "2  auburn  34590  2018.0         ford  f150 super cab xl pickup 4d       good   \n",
            "3  auburn  38990  2020.0         ford       f150 supercrew cab xlt       good   \n",
            "4  auburn  27990  2020.0         ford    ranger supercab xl pickup       good   \n",
            "\n",
            "     cylinders   fuel  odometer title_status transmission drive    type  \\\n",
            "0  6 cylinders    gas  128000.0        clean    automatic   rwd   truck   \n",
            "1          NaN  other    1834.0        clean        other   NaN  pickup   \n",
            "2  6 cylinders    gas   20856.0        clean        other   NaN  pickup   \n",
            "3  6 cylinders    gas   12231.0        clean        other   NaN  pickup   \n",
            "4          NaN    gas   10688.0        clean        other   NaN  pickup   \n",
            "\n",
            "  paint_color  \n",
            "0       black  \n",
            "1       black  \n",
            "2       white  \n",
            "3         NaN  \n",
            "4       white  \n",
            "region           object\n",
            "price             int64\n",
            "year            float64\n",
            "manufacturer     object\n",
            "model            object\n",
            "condition        object\n",
            "cylinders        object\n",
            "fuel             object\n",
            "odometer        float64\n",
            "title_status     object\n",
            "transmission     object\n",
            "drive            object\n",
            "type             object\n",
            "paint_color      object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-4315985ec716>:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_copy.fillna('unknown', inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time\n",
            "36.211474657058716\n",
            "Mean Squared Error: 28362706.905802667\n",
            "R-squared Score: 0.8416423913489381\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# Importing Zip file from Google Drive\n",
        "\n",
        "# Reading Data into Pandas Dataframe\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "DATADIR = \"/content/drive/MyDrive/vehicles.csv.zip\"\n",
        "\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "csv_file_name = 'vehicles.csv'\n",
        "\n",
        "# Create a ZipFile object and extract the CSV file\n",
        "with zipfile.ZipFile(DATADIR, 'r') as zip_file:\n",
        "    with zip_file.open(csv_file_name) as file:\n",
        "        # Read the CSV file with pandas\n",
        "        data = pd.read_csv(file)\n",
        "\n",
        "\n",
        "# Display the first few rows to understand the data\n",
        "data.columns\n",
        "print(data.head(5))\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "data.isna().sum()\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "data_copy = data\n",
        "\n",
        "\n",
        "data_types = data_copy.dtypes\n",
        "\n",
        "# Print the data types for all columns\n",
        "print(data_types)\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "data_copy = data_copy.dropna(subset=['year', 'odometer', 'manufacturer', 'model'])\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "data_copy.fillna('unknown', inplace=True)\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "data_copy = data_copy.drop_duplicates()\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "data_copy.shape\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "manufacturer_values = data_copy['manufacturer'].value_counts()\n",
        "data_copy['manufacturer'] =  data_copy['manufacturer'].apply(lambda x: x if str(x) in manufacturer_values[:20] else 'others')\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "region_values = data_copy['region'].value_counts()\n",
        "data_copy['region'] = data_copy['region'].apply(lambda x: x if str(x) in region_values[:50] else 'others')\n",
        "model_values = data_copy['model'].value_counts()\n",
        "data_copy['model'] = data_copy['model'].apply(lambda x: x if str(x) in model_values[:50] else 'others')\n",
        "\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "price_percentile25 = data_copy['price'].quantile(0.25)\n",
        "price_percentile75 = data_copy['price'].quantile(0.75)\n",
        "price_iqr = price_percentile75 - price_percentile25\n",
        "price_upper_limit = price_percentile75 + 1.5 * price_iqr\n",
        "price_lower_limit = data_copy['price'].quantile(0.15)\n",
        "new_df = data_copy[(data_copy['price'] < price_upper_limit) & (data_copy['price'] > price_lower_limit)]\n",
        "odometer_percentile75 = data_copy['odometer'].quantile(0.75)\n",
        "odometer_percentile25 = data_copy['odometer'].quantile(0.25)\n",
        "odometer_iqr = odometer_percentile75 - odometer_percentile25\n",
        "odometer_upper_limit = odometer_percentile75 + 1.5 * odometer_iqr\n",
        "odometer_lower_limit = data_copy['odometer'].quantile(0.05)\n",
        "new_df = new_df[(new_df['odometer'] < odometer_upper_limit) & (new_df['odometer'] > odometer_lower_limit)]\n",
        "\n",
        "\n",
        "# In[20]:\n",
        "\n",
        "\n",
        "new_df['odometer'] = new_df['odometer'].astype(int)\n",
        "new_df['year'] = new_df['year'].astype(int)\n",
        "\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "new_df = new_df[new_df['year'] > 1996]\n",
        "new_df.shape\n",
        "new_df['car_age'] = 2022 - new_df['year']\n",
        "new_df.drop(['year'], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "# Categorical to Numerical\n",
        "\n",
        "# In[23]:\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "pipe_categorical = Pipeline(\n",
        "    steps = [('ordinal_encoder', OrdinalEncoder(categories = [[ 'salvage', 'fair', 'unknown', 'good', 'excellent', 'like new', 'new']])),\n",
        "             ('one_hot_encoder', OneHotEncoder(sparse = False, drop = 'first'))]\n",
        ")\n",
        "pipe_numerical = Pipeline(\n",
        "    steps = [('standard_scaler', StandardScaler())]\n",
        ")\n",
        "column_transformer = ColumnTransformer(transformers = [\n",
        "    ('condition_pipe_trans', pipe_categorical['ordinal_encoder'], ['condition']),\n",
        "    ('categorical_pipe_trans', pipe_categorical['one_hot_encoder'], ['model', 'region', 'manufacturer', 'fuel', 'cylinders','title_status', 'transmission', 'drive', 'type', 'paint_color']),\n",
        "    ('numerical_pipe_trans', pipe_numerical, ['odometer'])\n",
        "])\n",
        "\n",
        "\n",
        "# Train & Test Data Split\n",
        "#\n",
        "\n",
        "# In[24]:\n",
        "\n",
        "\n",
        "final_df = new_df.copy()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_df.drop(['price'], axis = 1), final_df['price'], random_state = 42, test_size = .2)\n",
        "X_train_tnf = column_transformer.fit_transform(X_train)\n",
        "X_test_tnf = column_transformer.transform(X_test)\n",
        "\n",
        "\n",
        "# Training the Random Forest Regressor\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "# Create a Random Forest regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=150, random_state=0, min_samples_leaf=1, max_features=0.3, oob_score=True)\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "# Train the model\n",
        "rf_regressor.fit(X_train_tnf, y_train)\n",
        "end = time.time()\n",
        "print(\"Training time\")\n",
        "print(end - start)\n",
        "\n",
        "\n",
        "# Evaluation Model\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_regressor.predict(X_test_tnf)\n",
        "\n",
        "# Calculate the Mean Squared Error and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mAwwvx0d57MK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cyy_qapxQxG",
        "outputId": "ec7a0bec-f5dc-499c-8cf3-385176335f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-12-04 03:36:42,538\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPUs: 1\n",
            "Training time\n",
            "45.13707733154297\n",
            "Mean Squared Error: 28362706.905802667\n",
            "R-squared Score: 0.8416423913489381\n",
            "Number of CPUs: 2\n",
            "Training time\n",
            "43.77235007286072\n",
            "Mean Squared Error: 28362706.905802667\n",
            "R-squared Score: 0.8416423913489381\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create a Random Forest regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=150, random_state=0, min_samples_leaf=1, max_features=0.3, n_jobs=-1, oob_score=True)\n",
        "import time\n",
        "import joblib\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "start = time.time()\n",
        "from ray.util.joblib import register_ray\n",
        "register_ray()\n",
        "\n",
        "# Train the model\n",
        "for i in [1, 2]:\n",
        "  start = time.time()\n",
        "  with joblib.parallel_backend('ray', n_jobs = i):\n",
        "    rf_regressor.fit(X_train_tnf, y_train)\n",
        "  end = time.time()\n",
        "  print(\"Number of CPUs: \" + str(i))\n",
        "  print(\"Training time\")\n",
        "  print(end - start)\n",
        "\n",
        "  # Make predictions on the test set\n",
        "  y_pred = rf_regressor.predict(X_test_tnf)\n",
        "\n",
        "  # Calculate the Mean Squared Error and R-squared score\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "\n",
        "# Evaluation Model\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}